##
##  node1通过flume接收node2与node3中flume传来的数据，并将其分别发送至hbase与kafka中，配置内容如下
##
a1.sources=r1
a1.channels=kafkaC
a1.sinks=kafkaSink

a1.sources.r1.type=avro
a1.sources.r1.channels=kafkaC
a1.sources.r1.bind=127.0.0.1
a1.sources.r1.port=5555 
a1.sources.r1.threads=5 

##****************************flume + hbase******************************
#a1.channels.hbaseC.type = memory
#a1.channels.hbaseC.capacity = 10000
#a1.channels.hbaseC.transactionCapacity = 10000
#a1.channels.hbaseC.keep-alive = 20
#
#a1.sinks.hbaseSink.type = asynchbase
### HBase表名
#a1.sinks.hbaseSink.table = weblogs
### HBase表的列族名称
#a1.sinks.hbaseSink.columnFamily = info
#a1.sinks.hbaseSink.serializer = main.hbase.KfkAsyncHbaseEventSerializer
#a1.sinks.hbaseSink.channel = hbaseC
#a1.sinks.hbaseSink.serializer.payloadColumn = datetime,userid,searchname,retorder,cliorder,cliurl


#****************************flume + kafka******************************

a1.channels.kafkaC.type=memory
a1.channels.kafkaC.capacity=10000
a1.channels.kafkaC.transactionCapacity=10000
a1.channels.kafkaC.keep-alive=20

a1.sinks.kafkaSink.channel=kafkaC
a1.sinks.kafkaSink.type=com.vita.flume.sink.kafka.ReadAppKafkaSink
a1.sinks.kafkaSink.requiredAcks=1
a1.sinks.kafkaSink.batchSize=1

#a1.sinks.kafkaSink.serializer.class=kafka.serializer.StringEncoder
#a1.sinks.kafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
#a1.sinks.kafkaSink.brokerList = 127.0.0.1:9092
#a1.sinks.kafkaSink.topic = webCount
#a1.sinks.kafkaSink.zookeeperConnect = 127.0.0.1:2181
